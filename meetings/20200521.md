# jimmy

## Done

- OpenWorld Dataset
	- originally 7500 sites-> around 6950 sites left
	- remove Chinese websites(mostly are not accessible through tor)
	- remove duplicate websites(google.in, goole.br, etc..)
	- remove some inaccessible websites
	- remove websites that appears in closed-world dataset
- Crawler, pcap Parser integration
	- input weblist, output tar file including raw network traffic and stramInfo, log, errorList
- [Feature distribution visualization](https://drive.google.com/open?id=1hBkLJ5STDHTR52tE5Px5rd12dI17DB1U6heuhLMWb1A)
- Random Forrest Testing: accuracy 87 - 90%
	1. Remove Websites which has a median of packetNum less than 100
	2. Remove traffic instance that has 20% less packetNum comparing with the median of packetNum in the websites
	3. Remove websites that has less than n_threshold traffic instances left
	4. Around 175 sites left
	5. [TrafficResult-3](https://drive.google.com/open?id=1R7ZqTzOGg9bWMqB2kXvWoJQHLJJEZCjq)

## Todo

- Network Interface setup
- Construct Dataset for tbb version 8, version 7
- survey(see if there is any interesting measurement we can do)
	- statistic
	- ML techniques
	- sklearn document
	- [Info leaks of wf](https://arxiv.org/pdf/1710.06080.pdf)